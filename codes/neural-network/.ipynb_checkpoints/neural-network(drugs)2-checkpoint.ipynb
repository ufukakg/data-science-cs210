{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CS210\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier,export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import graphviz # anaconda prompt- pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydotplus # anaconda prompt- pip install pydotplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io \n",
    "from scipy import misc\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make results reproducible\n",
    "seed = 1234\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = '../../input/drug_data.csv'\n",
    "dataset = pd.read_csv(file, 'rb', delimiter =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "df = pd.DataFrame(dataset)\n",
    "cols = df.columns[1:13]\n",
    "for col in cols:\n",
    "    le.fit(dataset[col])\n",
    "    dataset[col] = le.transform(dataset[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = df.columns[13:]\n",
    "for col in cols:\n",
    "    dataset[col] = dataset[col].str.replace('CL','').astype(int)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = df.columns[13:]\n",
    "for col in cols:\n",
    "    if col != 'Alcohol':\n",
    "        df.__delitem__(col)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID',\n",
       " 'Age',\n",
       " 'Gender',\n",
       " 'Education',\n",
       " 'Country',\n",
       " 'Ethnicity',\n",
       " 'Nscore',\n",
       " 'Escore',\n",
       " 'Oscore',\n",
       " 'Ascore',\n",
       " 'Cscore',\n",
       " 'Impulsive',\n",
       " 'SS',\n",
       " 'Alcohol_0',\n",
       " 'Alcohol_1',\n",
       " 'Alcohol_2',\n",
       " 'Alcohol_3',\n",
       " 'Alcohol_4',\n",
       " 'Alcohol_5',\n",
       " 'Alcohol_6']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['Alcohol']) # One Hot Encoding\n",
    "values = list(dataset.columns.values)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  1.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  1.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset[values[13:]]\n",
    "y = np.array(y, dtype='float32')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   1.,   0., ...,   0.,   0.,   3.],\n",
       "       [  0.,   0.,   8., ...,   1.,   1.,   0.],\n",
       "       [  2.,   0.,   0., ...,   8.,   2.,   7.],\n",
       "       ..., \n",
       "       [  0.,   1.,   6., ...,  11.,   5.,   1.],\n",
       "       [  1.,   1.,   1., ...,  20.,   7.,   9.],\n",
       "       [  1.,   0.,   1., ...,  27.,   6.,   9.]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[values[1:13]]\n",
    "X = np.array(X, dtype='float32')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "1735\n"
     ]
    }
   ],
   "source": [
    "# Shuffle Data\n",
    "indices = np.random.choice(len(X), len(X), replace=False)\n",
    "X_values = X[indices]\n",
    "y_values = y[indices]\n",
    "\n",
    "# Creating a Train and a Test Dataset\n",
    "test_size = 150\n",
    "X_test = X_values[-test_size:]\n",
    "X_train = X_values[:-test_size]\n",
    "y_test = y_values[-test_size:]\n",
    "y_train = y_values[:-test_size]\n",
    "print(len(X_test))\n",
    "print(len(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CS210\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(768, input_dim=12, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\CS210\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(384, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# define the architecture of the network\n",
    "model = Sequential()\n",
    "model.add(Dense(768, input_dim=12, init=\"uniform\",\n",
    "\tactivation=\"relu\"))\n",
    "model.add(Dense(384, init=\"uniform\", activation=\"relu\"))\n",
    "model.add(Dense(7))\n",
    "model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CS210\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1735/1735 [==============================] - 0s 142us/step - loss: 0.3535 - acc: 0.8576\n",
      "Epoch 2/50\n",
      "1735/1735 [==============================] - 0s 47us/step - loss: 0.3387 - acc: 0.8568\n",
      "Epoch 3/50\n",
      "1735/1735 [==============================] - 0s 47us/step - loss: 0.3357 - acc: 0.8580\n",
      "Epoch 4/50\n",
      "1735/1735 [==============================] - 0s 54us/step - loss: 0.3346 - acc: 0.8587\n",
      "Epoch 5/50\n",
      "1735/1735 [==============================] - 0s 62us/step - loss: 0.3335 - acc: 0.8587\n",
      "Epoch 6/50\n",
      "1735/1735 [==============================] - 0s 63us/step - loss: 0.3326 - acc: 0.8599\n",
      "Epoch 7/50\n",
      "1735/1735 [==============================] - 0s 61us/step - loss: 0.3319 - acc: 0.8590\n",
      "Epoch 8/50\n",
      "1735/1735 [==============================] - 0s 58us/step - loss: 0.3324 - acc: 0.8585\n",
      "Epoch 9/50\n",
      "1735/1735 [==============================] - 0s 50us/step - loss: 0.3305 - acc: 0.8599\n",
      "Epoch 10/50\n",
      "1735/1735 [==============================] - 0s 54us/step - loss: 0.3309 - acc: 0.8590\n",
      "Epoch 11/50\n",
      "1735/1735 [==============================] - 0s 61us/step - loss: 0.3296 - acc: 0.8599\n",
      "Epoch 12/50\n",
      "1735/1735 [==============================] - 0s 66us/step - loss: 0.3297 - acc: 0.8590\n",
      "Epoch 13/50\n",
      "1735/1735 [==============================] - 0s 61us/step - loss: 0.3289 - acc: 0.8602\n",
      "Epoch 14/50\n",
      "1735/1735 [==============================] - 0s 58us/step - loss: 0.3286 - acc: 0.8604\n",
      "Epoch 15/50\n",
      "1735/1735 [==============================] - 0s 52us/step - loss: 0.3277 - acc: 0.8610\n",
      "Epoch 16/50\n",
      "1735/1735 [==============================] - 0s 53us/step - loss: 0.3291 - acc: 0.8592\n",
      "Epoch 17/50\n",
      "1735/1735 [==============================] - 0s 51us/step - loss: 0.3277 - acc: 0.8627\n",
      "Epoch 18/50\n",
      "1735/1735 [==============================] - 0s 50us/step - loss: 0.3275 - acc: 0.8614\n",
      "Epoch 19/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3273 - acc: 0.8616\n",
      "Epoch 20/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3270 - acc: 0.8605\n",
      "Epoch 21/50\n",
      "1735/1735 [==============================] - 0s 47us/step - loss: 0.3271 - acc: 0.8610\n",
      "Epoch 22/50\n",
      "1735/1735 [==============================] - 0s 47us/step - loss: 0.3264 - acc: 0.8606\n",
      "Epoch 23/50\n",
      "1735/1735 [==============================] - 0s 47us/step - loss: 0.3258 - acc: 0.8604\n",
      "Epoch 24/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3261 - acc: 0.8608\n",
      "Epoch 25/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3267 - acc: 0.8608\n",
      "Epoch 26/50\n",
      "1735/1735 [==============================] - 0s 50us/step - loss: 0.3251 - acc: 0.8612\n",
      "Epoch 27/50\n",
      "1735/1735 [==============================] - 0s 48us/step - loss: 0.3252 - acc: 0.8619\n",
      "Epoch 28/50\n",
      "1735/1735 [==============================] - 0s 48us/step - loss: 0.3254 - acc: 0.8625\n",
      "Epoch 29/50\n",
      "1735/1735 [==============================] - 0s 50us/step - loss: 0.3258 - acc: 0.8613\n",
      "Epoch 30/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3247 - acc: 0.8618\n",
      "Epoch 31/50\n",
      "1735/1735 [==============================] - 0s 48us/step - loss: 0.3256 - acc: 0.8610\n",
      "Epoch 32/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3243 - acc: 0.8632\n",
      "Epoch 33/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3248 - acc: 0.8608\n",
      "Epoch 34/50\n",
      "1735/1735 [==============================] - 0s 52us/step - loss: 0.3242 - acc: 0.8615\n",
      "Epoch 35/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3238 - acc: 0.8634\n",
      "Epoch 36/50\n",
      "1735/1735 [==============================] - 0s 51us/step - loss: 0.3235 - acc: 0.8626\n",
      "Epoch 37/50\n",
      "1735/1735 [==============================] - 0s 53us/step - loss: 0.3236 - acc: 0.8619\n",
      "Epoch 38/50\n",
      "1735/1735 [==============================] - 0s 50us/step - loss: 0.3232 - acc: 0.8619\n",
      "Epoch 39/50\n",
      "1735/1735 [==============================] - 0s 49us/step - loss: 0.3232 - acc: 0.8613\n",
      "Epoch 40/50\n",
      "1735/1735 [==============================] - 0s 64us/step - loss: 0.3229 - acc: 0.8630\n",
      "Epoch 41/50\n",
      "1735/1735 [==============================] - 0s 64us/step - loss: 0.3229 - acc: 0.8630\n",
      "Epoch 42/50\n",
      "1735/1735 [==============================] - 0s 62us/step - loss: 0.3225 - acc: 0.8628\n",
      "Epoch 43/50\n",
      "1735/1735 [==============================] - 0s 55us/step - loss: 0.3226 - acc: 0.8627\n",
      "Epoch 44/50\n",
      "1735/1735 [==============================] - 0s 53us/step - loss: 0.3226 - acc: 0.8625\n",
      "Epoch 45/50\n",
      "1735/1735 [==============================] - 0s 60us/step - loss: 0.3221 - acc: 0.8622\n",
      "Epoch 46/50\n",
      "1735/1735 [==============================] - 0s 55us/step - loss: 0.3226 - acc: 0.8615\n",
      "Epoch 47/50\n",
      "1735/1735 [==============================] - 0s 68us/step - loss: 0.3219 - acc: 0.8632\n",
      "Epoch 48/50\n",
      "1735/1735 [==============================] - 0s 63us/step - loss: 0.3221 - acc: 0.8619\n",
      "Epoch 49/50\n",
      "1735/1735 [==============================] - 0s 65us/step - loss: 0.3216 - acc: 0.8628\n",
      "Epoch 50/50\n",
      "1735/1735 [==============================] - 0s 59us/step - loss: 0.3216 - acc: 0.8621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18e67ba3cc0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using SGD\n",
    "print(\"[INFO] compiling model...\")\n",
    "sgd = SGD(lr=0.01)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, nb_epoch=50, batch_size=128,\n",
    "\tverbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating on testing set...\n",
      "150/150 [==============================] - 0s 214us/step\n",
      "[INFO] loss=0.3467, accuracy: 85.8095%\n"
     ]
    }
   ],
   "source": [
    "# show the accuracy on the testing set\n",
    "print(\"[INFO] evaluating on testing set...\")\n",
    "(loss, accuracy) = model.evaluate(X_test, y_test,\n",
    "\tbatch_size=128, verbose=1)\n",
    "print(\"[INFO] loss={:.4f}, accuracy: {:.4f}%\".format(loss,\n",
    "\taccuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Interval / Epochs\n",
    "interval = 50\n",
    "epoch = 500\n",
    "\n",
    "# Initialize placeholders\n",
    "X_data = tf.placeholder(shape=[None, 12], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None, 7], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input neurons : 4\n",
    "# Hidden neurons : 8\n",
    "# Output neurons : 3\n",
    "hidden_layer_nodes = 3\n",
    "\n",
    "# Create variables for Neural Network layers\n",
    "w1 = tf.Variable(tf.random_normal(shape=[12,hidden_layer_nodes])) # Inputs -> Hidden Layer\n",
    "b1 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes]))   # First Bias\n",
    "w2 = tf.Variable(tf.random_normal(shape=[hidden_layer_nodes,7])) # Hidden layer -> Outputs\n",
    "b2 = tf.Variable(tf.random_normal(shape=[7]))   # Second Bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Operations\n",
    "hidden_output = tf.nn.relu(tf.add(tf.matmul(X_data, w1), b1))\n",
    "final_output = tf.nn.softmax(tf.add(tf.matmul(hidden_output, w2), b2))\n",
    "\n",
    "# Cost Function\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_target * tf.log(final_output), axis=0))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n",
    "\n",
    "# Initialize variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 50 | Loss: nan\n",
      "Epoch 100 | Loss: nan\n",
      "Epoch 150 | Loss: nan\n",
      "Epoch 200 | Loss: nan\n",
      "Epoch 250 | Loss: nan\n",
      "Epoch 300 | Loss: nan\n",
      "Epoch 350 | Loss: nan\n",
      "Epoch 400 | Loss: nan\n",
      "Epoch 450 | Loss: nan\n",
      "Epoch 500 | Loss: nan\n",
      "\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  1.  0.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  1.  0.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  1.  0.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 1.  0.  0.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  1.  0.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  1.  0.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  1.  0.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  0.  1.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  0.  1.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n",
      "Actual: [ 0.  0.  0.  0.  1.  0.  0.] Predicted: [[ nan  nan  nan  nan  nan  nan  nan]]\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "print('Training the model...')\n",
    "for i in range(1, (epoch + 1)):\n",
    "    sess.run(optimizer, feed_dict={X_data: X_train, y_target: y_train})\n",
    "    if i % interval == 0:\n",
    "        print('Epoch', i, '|', 'Loss:', sess.run(loss, feed_dict={X_data: X_train, y_target: y_train}))\n",
    "\n",
    "# Prediction\n",
    "print()\n",
    "for i in range(len(X_test)):\n",
    "    print('Actual:', y_test[i], 'Predicted:', np.rint(sess.run(final_output, feed_dict={X_data: [X_test[i]]})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
